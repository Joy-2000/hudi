<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://hudi.apache.org/blog</id>
    <title>Apache Hudi: User-Facing Analytics</title>
    <updated>2024-12-06T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://hudi.apache.org/blog"/>
    <subtitle>Apache Hudi Blog</subtitle>
    <icon>https://hudi.apache.org/assets/images/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[Introducing Hudi's Non-blocking Concurrency Control for streaming, high-frequency writes]]></title>
        <id>https://hudi.apache.org/blog/2024/12/06/non-blocking-concurrency-control</id>
        <link href="https://hudi.apache.org/blog/2024/12/06/non-blocking-concurrency-control"/>
        <updated>2024-12-06T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Introduction]]></summary>
        <content type="html"><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="https://hudi.apache.org/blog/2024/12/06/non-blocking-concurrency-control#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">​</a></h2>
<p>In streaming ingestion scenarios, there are plenty of use cases that require concurrent ingestion from multiple streaming sources.
The user can union all the upstream source inputs into one downstream table to collect the records for unified access across federated queries.
Another very common scenario is multiple stream sources joined together to supplement dimensions of the records to build a wide-dimension table where each source
stream is taking records with partial table schema fields. Common and strong demand for multi-stream concurrent ingestion has always been there.
The Hudi community has collected so many feedbacks from users ever since the day Hudi supported streaming ingestion and processing.</p>
<p>Starting from <a href="https://hudi.apache.org/releases/release-1.0.0" target="_blank" rel="noopener noreferrer">Hudi 1.0.0</a>, we are thrilled to announce a new general-purpose
concurrency model for Apache Hudi - the Non-blocking Concurrency Control (NBCC)- aimed at the stream processing or high-contention/frequent writing scenarios.
In contrast to <a href="https://hudi.apache.org/blog/2021/12/16/lakehouse-concurrency-control-are-we-too-optimistic/">Optimistic Concurrency Control</a>, where writers abort the transaction
if there is a hint of contention, this innovation allows multiple streaming writes to the same Hudi table without any overhead of conflict resolution, while
keeping the semantics of <a href="https://www.oreilly.com/radar/the-world-beyond-batch-streaming-101/" target="_blank" rel="noopener noreferrer">event-time ordering</a> found in streaming systems, along with
asynchronous table service such as compaction, archiving and cleaning.</p>
<p>NBCC works seamlessly without any new infrastructure or operational overhead. In the subsequent sections of this blog, we will give a brief introduction to Hudi's internals
about the data file layout and TrueTime semantics for time generation, a pre-requisite for discussing NBCC. Following that, we will delve into the design and workflows of NBCC,
and then a simple SQL demo to show the NBCC related config options. The blog will conclude with insights into future work for NBCC.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="older-design">Older Design<a href="https://hudi.apache.org/blog/2024/12/06/non-blocking-concurrency-control#older-design" class="hash-link" aria-label="Direct link to Older Design" title="Direct link to Older Design">​</a></h2>
<p>It's important to understand the Hudi <a href="https://hudi.apache.org/docs/next/storage_layouts">storage layout</a> and it evolves/manages data versions. In older release before 1.0.0,
Hudi organizes the data files with units as <code>FileGroup</code>. Each file group contains multiple <code>FileSlice</code>s. Every compaction on this file group generates a new file slice.
Each file slice may comprise an optional base file(columnar file format like Apache Parquet or ORC) and multiple log files(row file format in Apache Avro or Parquet).</p>
<img src="https://hudi.apache.org/assets/images/blog/non-blocking-concurrency-control/legacy_file_layout.png" alt="Legacy file layout" width="800" align="middle">
<p>The timestamp in the base file name is the instant time of the compaction that writes it, it is also called as "requested instant time" in Hudi's notion.
The timestamp in the log file name is the same timestamp as the current file slice base instant time. Data files with the same instant time belong to one file slice.
In effect, a file group represented a linear ordered sequence of base files (checkpoints) followed by logs files (deltas), followed by base files (checkpoints).</p>
<p>The instant time naming convention in log files becomes a hash limitation in concurrency mode. Each log file contains incremental changes from
multiple commits. Each writer needs to query the file layout to get the base instant time and figure out the full file name before flushing the records.
A more severe problem is the base instant time can be variable with the async compaction pushing forward. In order to make the base instant time deterministic for the log writers, Hudi
forces the schedule sequence between a write commit and compaction scheduling: a compaction can be scheduled only if there is no ongoing ingestion into the Hudi table. Without this, a log file
can be written with a wrong base instant time which could introduce data loss. This means a compaction scheduling could block all the writers in concurrency mode.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="nbcc-design">NBCC Design<a href="https://hudi.apache.org/blog/2024/12/06/non-blocking-concurrency-control#nbcc-design" class="hash-link" aria-label="Direct link to NBCC Design" title="Direct link to NBCC Design">​</a></h2>
<p>In order to resolve these pains, since 1.0.0, Hudi introduces a new storage layout based on both requested and completion times of actions, viewing them as an interval.
Each commit in 1.x Hudi has two <a href="https://hudi.apache.org/docs/next/timeline">important notions of time</a>: instant time(or requested time) and completion time.
All the generated timestamp are globally monotonically increasing. Instead of putting the base instant time in the log file name, Hudi now just uses the requested instant time
of the write. During file slicing, Hudi queries the completion time for each log file with the instant time, and we have a new rule for file slicing:</p>
<p><em>A log file belongs to the file slice with the maximum base requested time smaller than(or equals with) it's completion time.</em>[^1]</p>
<img src="https://hudi.apache.org/assets/images/blog/non-blocking-concurrency-control/new_file_layout.png" alt="New file layout" width="800" align="middle">
<p>With the flexibility of the new file layout, the overhead of querying base instant time is eliminated for log writers and a compaction can be scheduled anywhere with any instant time.
See <a href="https://github.com/apache/hudi/blob/master/rfc/rfc-66/rfc-66.md" target="_blank" rel="noopener noreferrer">RFC-66</a> for more.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="true-time-api">True Time API<a href="https://hudi.apache.org/blog/2024/12/06/non-blocking-concurrency-control#true-time-api" class="hash-link" aria-label="Direct link to True Time API" title="Direct link to True Time API">​</a></h3>
<p>In order to ensure the monotonicity of timestamp generation, Hudi introduces the "<a href="https://hudi.apache.org/docs/next/timeline#timeline-components">TrueTime API</a>" since 1.x release.
Basically there are two ways to make the time generation monotonically increasing, inline with TrueTime semantics:</p>
<ul>
<li>A global lock to guard the time generation with mutex, along with a wait for an estimated max allowed clock skew on distributed hosts;</li>
<li>Globally synchronized time generation service, e.g. Google Spanner Time Service, the service itself can ensure the monotonicity.</li>
</ul>
<p>Hudi now implements the "TrueTime" semantics with the first solution, a configurable max waiting time is supported.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="lsm-timeline">LSM timeline<a href="https://hudi.apache.org/blog/2024/12/06/non-blocking-concurrency-control#lsm-timeline" class="hash-link" aria-label="Direct link to LSM timeline" title="Direct link to LSM timeline">​</a></h3>
<p>The new file layout requires efficient queries from instant time to get the completion time. Hudi re-implements the archived timeline since 1.x, the
new archived timeline data files are organized as <a href="https://hudi.apache.org/docs/next/timeline#lsm-timeline-history">an LSM tree</a> to support fast time range filtering queries with instant time data-skipping on it.</p>
<img src="https://hudi.apache.org/assets/images/blog/non-blocking-concurrency-control/lsm_archive_timeline.png" alt="LSM archive timeline" align="middle">
<p>With the powerful new file layout, it is quite straight-forward to implement non-blocking concurrency control. The function is implemented with the simple bucket index on MOR table for Flink.
The bucket index ensures fixed record key to file group mappings for multiple workloads. The log writer writes the records into avro logs and the compaction table service would take care of
the conflict resolution. Because each log file name contains the instant time and each record contains the event time ordering field, Hudi reader can merge the records either
with natural order(processing time sequence) or event time order.</p>
<p>The concurrency mode should be configured as <code>NON_BLOCKING_CONCURRENCY_CONTROL</code>, you can enable the table services on one job and disable it for the others.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="flink-sql-demo">Flink SQL demo<a href="https://hudi.apache.org/blog/2024/12/06/non-blocking-concurrency-control#flink-sql-demo" class="hash-link" aria-label="Direct link to Flink SQL demo" title="Direct link to Flink SQL demo">​</a></h2>
<p>Here is a demo to show 2 pipelines that ingest into the same downstream table, the two sink table views share the same table path.</p>
<div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)">-- NB-CC demo</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- The source table</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> sourceT </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  uuid </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">20</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">10</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  age </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  ts </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">timestamp</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">3</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">partition</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">as</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'par1'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WITH</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'connector'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'datagen'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'rows-per-second'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'200'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- table view for writer1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">create</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">table</span><span class="token plain"> t1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  uuid </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">20</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">10</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  age </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  ts </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">timestamp</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">3</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">partition</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">20</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">with</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'connector'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'hudi'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'path'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'/Users/chenyuzhao/workspace/hudi-demo/t1'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'table.type'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'MERGE_ON_READ'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'index.type'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'BUCKET'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'hoodie.write.concurrency.mode'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'NON_BLOCKING_CONCURRENCY_CONTROL'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'write.tasks'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'2'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">insert</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">into</span><span class="token plain"> t1</span><span class="token comment" style="color:rgb(98, 114, 164)">/*+options('metadata.enabled'='true')*/</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">select</span><span class="token plain"> </span><span class="token operator">*</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> sourceT</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- table view for writer2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- compaction and cleaning are disabled because writer1 has taken care of it.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">create</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">table</span><span class="token plain"> t1_2</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  uuid </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">20</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">10</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  age </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  ts </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">timestamp</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">3</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">partition</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">20</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">with</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'connector'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'hudi'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'path'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'/Users/chenyuzhao/workspace/hudi-demo/t1'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'table.type'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'MERGE_ON_READ'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'index.type'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'BUCKET'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'hoodie.write.concurrency.mode'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'NON_BLOCKING_CONCURRENCY_CONTROL'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'write.tasks'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'2'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'compaction.schedule.enabled'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'false'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'compaction.async.enabled'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'false'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'clean.async.enabled'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'false'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- executes the ingestion workloads</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">insert</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">into</span><span class="token plain"> t1 </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">select</span><span class="token plain"> </span><span class="token operator">*</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> sourceT</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">insert</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">into</span><span class="token plain"> t1_2 </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">select</span><span class="token plain"> </span><span class="token operator">*</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> sourceT</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="future-roadmap">Future Roadmap<a href="https://hudi.apache.org/blog/2024/12/06/non-blocking-concurrency-control#future-roadmap" class="hash-link" aria-label="Direct link to Future Roadmap" title="Direct link to Future Roadmap">​</a></h2>
<p>While non-blocking concurrency control is a very powerful feature for streaming users, it is a general solution for multiple writer conflict resolution,
here are some plans that improve the Hudi core features:</p>
<ul>
<li>NBCC support for metadata table</li>
<li>NBCC for clustering</li>
<li>NBCC for other index type</li>
</ul>
<hr>
<p>[^1] <a href="https://github.com/apache/hudi/blob/master/rfc/rfc-66/rfc-66.md" target="_blank" rel="noopener noreferrer">RFC-66</a> well-explained the completion time based file slicing with a pseudocode.</p>]]></content>
        <author>
            <name>Danny Chan</name>
        </author>
        <category label="design" term="design"/>
        <category label="streaming ingestion" term="streaming ingestion"/>
        <category label="multi-writer" term="multi-writer"/>
        <category label="concurrency-control" term="concurrency-control"/>
        <category label="blog" term="blog"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hudi’s Automatic File Sizing Delivers Unmatched Performance]]></title>
        <id>https://hudi.apache.org/blog/2024/11/19/automated-small-file-handling</id>
        <link href="https://hudi.apache.org/blog/2024/11/19/automated-small-file-handling"/>
        <updated>2024-11-19T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Introduction]]></summary>
        <content type="html"><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="https://hudi.apache.org/blog/2024/11/19/automated-small-file-handling#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">​</a></h2>
<p>In today’s data-driven world, managing large volumes of data efficiently is crucial. One of the standout features of Apache Hudi is its ability to handle small files during data writes, which significantly optimizes both performance and cost. In this post, we’ll explore how Hudi’s auto file sizing, powered by a unique bin packing algorithm, can transform your data processing workflows.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="understanding-small-file-challenges">Understanding Small File Challenges<a href="https://hudi.apache.org/blog/2024/11/19/automated-small-file-handling#understanding-small-file-challenges" class="hash-link" aria-label="Direct link to Understanding Small File Challenges" title="Direct link to Understanding Small File Challenges">​</a></h2>
<p>In big data environments, small files can pose a major challenge. Some major use-cases which can create lot of small files -</p>
<ul>
<li><strong>Streaming Workloads</strong> :
When data is ingested in micro-batches, as is common in streaming workloads, the resulting files tend to be small. This can lead to a significant number of small files, especially for high-throughput streaming applications.</li>
<li><strong>High-Cardinality Partitioning</strong> :
Excessive partitioning, particularly on columns with high cardinality, can create a large number of small files. This can be especially problematic when dealing with large datasets and complex data schemas.</li>
</ul>
<p>These small files can lead to several inefficiencies that can include increased metadata overhead, degraded read performance, and higher storage costs, particularly when using cloud storage solutions like Amazon S3.</p>
<ul>
<li><strong>Increased Metadata Overhead</strong> :
Metadata is data about data, including information such as file names, sizes, creation dates, and other attributes that help systems manage and locate files. Each file, no matter how small, requires metadata to be tracked and managed. In environments where numerous small files are created, the amount of metadata generated can skyrocket. For instance, if a dataset consists of thousands of tiny files, the system must maintain metadata for each of these files. This can overwhelm metadata management systems, leading to longer lookup times and increased latency when accessing files.</li>
<li><strong>Degraded Read Performance</strong> :
Reading data from storage typically involves input/output (I/O) operations, which can be costly in terms of time and resources. When files are small, the number of I/O operations increases, as each small file needs to be accessed individually. This scenario can create bottlenecks, particularly in analytical workloads where speed is critical. Querying a large number of small files may result in significant delays, as the system spends more time opening and reading each file than processing the data itself.</li>
<li><strong>Higher Cloud Costs</strong> :
Many cloud storage solutions, like Amazon S3, charge based on the total amount of data stored as well as the number of requests made. With numerous small files, not only does the total storage requirement increase, but the number of requests to access these files also grows. Each small file incurs additional costs due to the overhead associated with managing and accessing them. This can add up quickly, leading to unexpectedly high storage bills.</li>
<li><strong>High Query Load</strong> :
Multiple teams are querying these tables for various dashboards, ad-hoc analyses, and machine learning tasks. This leads to a high number of concurrent queries, including Spark jobs, which can significantly impact performance. All those queries/jobs will take a hit on both performance and cost.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="impact-of-small-file">Impact of Small File<a href="https://hudi.apache.org/blog/2024/11/19/automated-small-file-handling#impact-of-small-file" class="hash-link" aria-label="Direct link to Impact of Small File" title="Direct link to Impact of Small File">​</a></h3>
<p>To demonstrate the impact of small files, we conducted a benchmarking using AWS EMR.
Dataset Used - TPC-DS 1 TB dataset ( <a href="https://www.tpc.org/tpcds/" target="_blank" rel="noopener noreferrer">https://www.tpc.org/tpcds/</a> )
Cluster Configurations - 10 nodes (m5.4xlarge)
Spark Configurations - Executors: 10 (16 cores 32 GB memory)
Dataset Generation - We generated two types of datasets in parquet format</p>
<ul>
<li>Optimized File Sizes which had ~100 MB sized files</li>
<li>Small File Sizes which had ~5-10 MB sized files
Execution and Results</li>
<li>We executed 3 rounds of 99 standard TPC-DS queries on both datasets and measured the time taken by the queries.</li>
<li>The results indicated that queries executed on small files were, on average, 30% slower compared to those executed on optimized file sizes.</li>
</ul>
<p>The following chart illustrates the average runtimes for the 99 queries across each round.</p>
<p><img decoding="async" loading="lazy" alt="Impact of Small Files" src="https://hudi.apache.org/assets/images/2024-11-19-automated-small-file-handling-benchmarks-5340e7e5e0e586c3803f6e06796b5daf.png" width="3188" height="1844" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-table-formats-solve-this-problem">How table formats solve this problem<a href="https://hudi.apache.org/blog/2024/11/19/automated-small-file-handling#how-table-formats-solve-this-problem" class="hash-link" aria-label="Direct link to How table formats solve this problem" title="Direct link to How table formats solve this problem">​</a></h2>
<p>When it comes to managing small files in table formats, there are two primary strategies:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ingesting-data-as-is-and-optimizing-post-ingestion-"><strong>Ingesting Data As-Is and Optimizing Post-Ingestion</strong> :<a href="https://hudi.apache.org/blog/2024/11/19/automated-small-file-handling#ingesting-data-as-is-and-optimizing-post-ingestion-" class="hash-link" aria-label="Direct link to ingesting-data-as-is-and-optimizing-post-ingestion-" title="Direct link to ingesting-data-as-is-and-optimizing-post-ingestion-">​</a></h3>
<p>In this approach, data, including small files, is initially ingested without immediate processing. After ingestion, various technologies provide functionalities to merge these small files into larger, more efficient partitions:</p>
<ul>
<li>Hudi uses clustering to manage small files.</li>
<li>Delta Lake utilizes the OPTIMIZE command.</li>
<li>Iceberg offers the rewrite_data_files function.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="pros">Pros:<a href="https://hudi.apache.org/blog/2024/11/19/automated-small-file-handling#pros" class="hash-link" aria-label="Direct link to Pros:" title="Direct link to Pros:">​</a></h4>
<ul>
<li>Writing small files directly accelerates the ingestion process, enabling quick data availability—especially beneficial for real-time or near-real-time applications.</li>
<li>The initial write phase involves less data manipulation, as small files are simply appended. This streamlines workflows and eases the management of incoming data streams.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="cons">Cons:<a href="https://hudi.apache.org/blog/2024/11/19/automated-small-file-handling#cons" class="hash-link" aria-label="Direct link to Cons:" title="Direct link to Cons:">​</a></h4>
<ul>
<li>Until clustering or optimization is performed, small files may be exposed to readers, which can significantly slow down queries and potentially violate read SLAs.</li>
<li>Just like with read performance, exposing small files to readers can lead to a high number of cloud storage API calls, which can increase cloud costs significantly.</li>
<li>Managing table service jobs can become cumbersome. These jobs often can't run in parallel with ingestion tasks, leading to potential delays and resource contention.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="managing-small-files-during-ingestion-only-"><strong>Managing Small Files During Ingestion Only</strong> :<a href="https://hudi.apache.org/blog/2024/11/19/automated-small-file-handling#managing-small-files-during-ingestion-only-" class="hash-link" aria-label="Direct link to managing-small-files-during-ingestion-only-" title="Direct link to managing-small-files-during-ingestion-only-">​</a></h3>
<p>Hudi offers a unique functionality that can handle small files during the ingestion only, ensuring that only larger files are stored in the table. This not only optimizes read performance but also significantly reduces storage costs.
By eliminating small files from the lake, Hudi addresses key challenges associated with data management, providing a streamlined solution that enhances both performance and cost efficiency.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-hudi-helps-in-small-file-handling-during-ingestion">How Hudi helps in small file handling during ingestion<a href="https://hudi.apache.org/blog/2024/11/19/automated-small-file-handling#how-hudi-helps-in-small-file-handling-during-ingestion" class="hash-link" aria-label="Direct link to How Hudi helps in small file handling during ingestion" title="Direct link to How Hudi helps in small file handling during ingestion">​</a></h2>
<p>Hudi automatically manages file sizing during insert and upsert operations. It employs a bin packing algorithm to handle small files effectively. A bin packing algorithm is a technique used to optimize file storage by grouping files of varying sizes into fixed-size containers, often referred to as "bins." This strategy aims to minimize the number of bins required to store all files efficiently. When writing data, Hudi identifies file groups of small files and merges new data into the same  group, resulting in optimized file sizes.</p>
<p>The diagram above illustrates how Hudi employs a bin packing algorithm to manage small files while using default parameters: a small file limit of 100 MB and a maximum file size of 120 MB.</p>
<p><img decoding="async" loading="lazy" alt="  " src="https://hudi.apache.org/assets/images/2024-11-19-automated-small-file-handling-process-676b9be484af36088162dfaf6a219a1f.png" width="1350" height="632" class="img_ev3q"></p>
<p>Initially, the table contains the following files: F1 (110 MB), F2 (60 MB), F3 (20 MB), and F4 (20 MB).
After processing a batch-1 of 150 MB, F2, F3, and F4 will all be classified as small files since they each fall below the 100 MB threshold. The first 60 MB will be allocated to F2, increasing its size to 120 MB. The remaining 90 MB will be assigned to F3, bringing its total to 110 MB.
After processing batch-2 of 150 MB, only F4 will be classified as a small file. F3, now at 110 MB, will not be considered a small file since it exceeds the 100 MB limit. Therefore, an additional 100 MB will be allocated to F4, increasing its size to 120 MB, while the remaining 50 MB will create a new file of 50 MB.
We can refer this blog for in-depth details of the functionality  - <a href="https://hudi.apache.org/blog/2021/03/01/hudi-file-sizing/" target="_blank" rel="noopener noreferrer">https://hudi.apache.org/blog/2021/03/01/hudi-file-sizing/</a></p>
<p>We use following configs to configure this -</p>
<ul>
<li>
<p><strong>Hoodie.parquet.max.file.size (Default 128 MB)</strong>
This setting specifies the target size, in bytes, for Parquet files generated during Hudi write phases. The writer will attempt to create files that approach this target size. For example, if an existing file is 80 MB, the writer will allocate only 40 MB to that particular file group.</p>
</li>
<li>
<p><strong>Hoodie.parquet.small.file.limit (Default 100 MB)</strong>
This setting defines the maximum file size for a data file to be classified as a small file. Files below this threshold are considered small files, prompting the system to allocate additional records to their respective file groups in subsequent write phases.</p>
</li>
<li>
<p><strong>hoodie.copyonwrite.record.size.estimate (Default 1024)</strong>
This setting represents the estimated average size of a record. If not explicitly specified, Hudi will dynamically compute this estimate based on commit metadata. Accurate record size estimation is essential for determining insert parallelism and efficiently bin-packing inserts into smaller files.</p>
</li>
<li>
<p><strong>hoodie.copyonwrite.insert.split.size (Default 500000)</strong>
This setting determines the number of records inserted into each partition or bucket during a write operation. The default value is based on the assumption of 100MB files with at least 1KB records, resulting in approximately 100,000 records per file. To accommodate potential variations, we overprovision to 500,000 records. As long as auto-tuning of splits is turned on, this only affects the first write, where there is no history to learn record sizes from.</p>
</li>
<li>
<p><strong>hoodie.merge.small.file.group.candidates.limit (Default1)</strong>
This setting specifies the maximum number of file groups whose base files meet the small-file limit that can be considered for appending records during an upsert operation. This parameter is applicable only to Merge-On-Read (MOR) tables.</p>
</li>
</ul>
<p>We can refer this blog to understand internal functionality how it works -
<a href="https://hudi.apache.org/blog/2021/03/01/hudi-file-sizing/#during-write-vs-after-write" target="_blank" rel="noopener noreferrer">https://hudi.apache.org/blog/2021/03/01/hudi-file-sizing/#during-write-vs-after-write</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://hudi.apache.org/blog/2024/11/19/automated-small-file-handling#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>Hudi's innovative approach to managing small files during ingestion positions it as a compelling choice in the lakehouse landscape. By automatically merging small files at the time of ingestion, it optimizes storage costs and enhances read performance, and alleviates users from the operational burden of maintaining their tables in an optimized state.</p>
<p>Unleash the power of Apache Hudi for your big data challenges! Head over to <a href="https://hudi.apache.org/" target="_blank" rel="noopener noreferrer">https://hudi.apache.org/</a> and dive into the quickstarts to get started. Want to learn more? Join our vibrant Hudi community! Attend the monthly Community Call or hop into the Apache Hudi Slack to ask questions and gain deeper insights.</p>]]></content>
        <author>
            <name>Aditya Goenka</name>
        </author>
        <category label="Data Lake" term="Data Lake"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Record Level Indexing in Apache Hudi]]></title>
        <id>https://hudi.apache.org/blog/2024/11/12/record-level-indexing-in-apache-hudi</id>
        <link href="https://hudi.apache.org/blog/2024/11/12/record-level-indexing-in-apache-hudi"/>
        <updated>2024-11-12T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://medium.com/@prasadpal107/record-level-indexing-in-apache-hudi-0615804608ec">here</a></span>]]></content>
        <author>
            <name>Bibhu Pala</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="apache hudi" term="apache hudi"/>
        <category label="record index" term="record index"/>
        <category label="record level index" term="record level index"/>
        <category label="medium" term="medium"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Storing 200 Billion Entities: Notion’s Data Lake Project]]></title>
        <id>https://hudi.apache.org/blog/2024/11/12/storing-200-billion-entities-notions</id>
        <link href="https://hudi.apache.org/blog/2024/11/12/storing-200-billion-entities-notions"/>
        <updated>2024-11-12T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://blog.bytebytego.com/p/storing-200-billion-entities-notions">here</a></span>]]></content>
        <author>
            <name>ByteByteGo</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="apache hudi" term="apache hudi"/>
        <category label="use-case" term="use-case"/>
        <category label="bytebytego" term="bytebytego"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding COW and MOR in Apache Hudi: Choosing the Right Storage Strategy]]></title>
        <id>https://hudi.apache.org/blog/2024/11/12/understanding-cow-and-mor-in-apache-hudi</id>
        <link href="https://hudi.apache.org/blog/2024/11/12/understanding-cow-and-mor-in-apache-hudi"/>
        <updated>2024-11-12T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://opstree.com/blog/2024/11/12/understanding-cow-and-mor-in-apache-hudi-choosing-the-right-storage-strategy/">here</a></span>]]></content>
        <author>
            <name>Deepak Nishad</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="apache hudi" term="apache hudi"/>
        <category label="cow" term="cow"/>
        <category label="mor" term="mor"/>
        <category label="opstree" term="opstree"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[I spent 5 hours exploring the story behind Apache Hudi.]]></title>
        <id>https://hudi.apache.org/blog/2024/10/27/I-spent-5-hours-exploring-the-story-behind-Apache-Hudi</id>
        <link href="https://hudi.apache.org/blog/2024/10/27/I-spent-5-hours-exploring-the-story-behind-Apache-Hudi"/>
        <updated>2024-10-27T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://blog.det.life/i-spent-5-hours-exploring-the-story-behind-apache-hudi-dacad829394d">here</a></span>]]></content>
        <author>
            <name>Vu Trinh</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="apache hudi" term="apache hudi"/>
        <category label="beginner" term="beginner"/>
        <category label="det" term="det"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Moving Large Tables from Snowflake to S3 Using the COPY INTO Command and Hudi Bootstrapping to Build Data Lakes | Hands-On Labs]]></title>
        <id>https://hudi.apache.org/blog/2024/10/26/moving-large-tables-from-snowflake-to-s3-using-the-copy-into-command-and-hudi</id>
        <link href="https://hudi.apache.org/blog/2024/10/26/moving-large-tables-from-snowflake-to-s3-using-the-copy-into-command-and-hudi"/>
        <updated>2024-10-26T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://www.linkedin.com/pulse/moving-large-tables-from-snowflake-s3-using-copy-command-soumil-shah-csdse/?trackingId=8qFtCUc3R7CAo%2BP883rgUA%3D%3D">here</a></span>]]></content>
        <author>
            <name>Soumil Shah</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="aws s3" term="aws s3"/>
        <category label="bootstrap" term="bootstrap"/>
        <category label="linkedin" term="linkedin"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using Apache Hudi with Apache Flink]]></title>
        <id>https://hudi.apache.org/blog/2024/10/23/Using-Apache-Hudi-with-Apache-Flink</id>
        <link href="https://hudi.apache.org/blog/2024/10/23/Using-Apache-Hudi-with-Apache-Flink"/>
        <updated>2024-10-23T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://docs.aws.amazon.com/emr/latest/EMR-on-EKS-DevelopmentGuide/tutorial-hudi-for-flink.html">here</a></span>]]></content>
        <author>
            <name>amazon</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="apache hudi" term="apache hudi"/>
        <category label="apache flink" term="apache flink"/>
        <category label="beginner" term="beginner"/>
        <category label="aws" term="aws"/>
        <category label="amazon" term="amazon"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mastering Open Table Formats: A Guide to Apache Iceberg, Hudi, and Delta Lake]]></title>
        <id>https://hudi.apache.org/blog/2024/10/23/mastering-open-table-formats-a-guide-to-apache-iceberg-hudi-and-delta-lake</id>
        <link href="https://hudi.apache.org/blog/2024/10/23/mastering-open-table-formats-a-guide-to-apache-iceberg-hudi-and-delta-lake"/>
        <updated>2024-10-23T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://medium.com/itversity/understanding-open-table-formats-a-comprehensive-guide-ba6f072167fb">here</a></span>]]></content>
        <author>
            <name>Naresh Dulam</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="Apache Iceberg" term="Apache Iceberg"/>
        <category label="Delta Lake" term="Delta Lake"/>
        <category label="comparison" term="comparison"/>
        <category label="medium" term="medium"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring Time Travel Queries in Apache Hudi]]></title>
        <id>https://hudi.apache.org/blog/2024/10/22/exploring-time-travel-queries-in-apache-hudi</id>
        <link href="https://hudi.apache.org/blog/2024/10/22/exploring-time-travel-queries-in-apache-hudi"/>
        <updated>2024-10-22T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://opstree.com/blog/2024/10/22/time-travel-queries-in-apache-hudi/">here</a></span>]]></content>
        <author>
            <name>Ramneek Kaur</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="time travel query" term="time travel query"/>
        <category label="opstree" term="opstree"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Streaming DynamoDB Data into a Hudi Table: AWS Glue in Action]]></title>
        <id>https://hudi.apache.org/blog/2024/10/14/streaming-dynamodb-data-into-a-hudi-table-aws-glue-in-action</id>
        <link href="https://hudi.apache.org/blog/2024/10/14/streaming-dynamodb-data-into-a-hudi-table-aws-glue-in-action"/>
        <updated>2024-10-14T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://www.antstack.com/blog/Streaming-DynamoDB-Data-into-a-Hudi-Table/">here</a></span>]]></content>
        <author>
            <name>Rahul Kumar</name>
        </author>
        <category label="how-to" term="how-to"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="amazon s3" term="amazon s3"/>
        <category label="aws glue" term="aws glue"/>
        <category label="amazon kinesis" term="amazon kinesis"/>
        <category label="amazon dynamodb" term="amazon dynamodb"/>
        <category label="antstack" term="antstack"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Iceberg vs. Delta Lake vs. Hudi: A Comparative Look at Lakehouse Architectures]]></title>
        <id>https://hudi.apache.org/blog/2024/10/07/iceberg-vs-delta-lake-vs-hudi-a-comparative-look-at-lakehouse-architectures</id>
        <link href="https://hudi.apache.org/blog/2024/10/07/iceberg-vs-delta-lake-vs-hudi-a-comparative-look-at-lakehouse-architectures"/>
        <updated>2024-10-07T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://blog.forefathers.io/iceberg-vs-delta-lake-vs-hudi-a-comparative-look-at-lakehouse-architectures-52eec62b29e8">here</a></span>]]></content>
        <author>
            <name>Abdelkbir Armel</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="Apache Iceberg" term="Apache Iceberg"/>
        <category label="Delta Lake" term="Delta Lake"/>
        <category label="comparison" term="comparison"/>
        <category label="forefathers" term="forefathers"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mastering Slowly Changing Dimensions with Apache Hudi & Spark SQL]]></title>
        <id>https://hudi.apache.org/blog/2024/10/07/mastering-slowly-changing-dimensions-with-apache-hudi-and-spark-sql</id>
        <link href="https://hudi.apache.org/blog/2024/10/07/mastering-slowly-changing-dimensions-with-apache-hudi-and-spark-sql"/>
        <updated>2024-10-07T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://www.linkedin.com/pulse/mastering-slowly-changing-dimensions-apache-hudi-spark-sameer-shaik-7zkjf/?trackingId=1qCeO8FIRJy32LcpHIvy3Q%3D%3D">here</a></span>]]></content>
        <author>
            <name>Sameer Shaik</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="scd1" term="scd1"/>
        <category label="scd2" term="scd2"/>
        <category label="scd3" term="scd3"/>
        <category label="spark-sql" term="spark-sql"/>
        <category label="linkedin" term="linkedin"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Hudi, Spark and Minio: Hands-on Lab in Docker]]></title>
        <id>https://hudi.apache.org/blog/2024/10/02/apache-hudi-spark-and-minio-hands-on-lab-in-docker</id>
        <link href="https://hudi.apache.org/blog/2024/10/02/apache-hudi-spark-and-minio-hands-on-lab-in-docker"/>
        <updated>2024-10-02T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://blog.devgenius.io/apache-hudi-spark-and-minio-hands-on-lab-in-docker-f1daa099ccd0">here</a></span>]]></content>
        <author>
            <name>Sanjeet Shukla</name>
        </author>
        <category label="how-to" term="how-to"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="Apache Spark" term="Apache Spark"/>
        <category label="Minio" term="Minio"/>
        <category label="docker" term="docker"/>
        <category label="devgenius" term="devgenius"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Change query support in Apache Hudi (0.15)]]></title>
        <id>https://hudi.apache.org/blog/2024/09/30/change-query-support-in-apache-hudi-0-15</id>
        <link href="https://hudi.apache.org/blog/2024/09/30/change-query-support-in-apache-hudi-0-15"/>
        <updated>2024-09-30T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://jack-vanlightly.com/analyses/2024/9/27/change-query-support-in-apache-hudi">here</a></span>]]></content>
        <author>
            <name>Jack Vanlightly</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="apache hudi" term="apache hudi"/>
        <category label="CDC" term="CDC"/>
        <category label="Change Data Capture" term="Change Data Capture"/>
        <category label="jack-vanlightly" term="jack-vanlightly"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hudi, Iceberg and Delta Lake: Data Lake Table Formats Compared]]></title>
        <id>https://hudi.apache.org/blog/2024/09/24/hudi-iceberg-and-delta-lake-data-lake-table-formats-compared</id>
        <link href="https://hudi.apache.org/blog/2024/09/24/hudi-iceberg-and-delta-lake-data-lake-table-formats-compared"/>
        <updated>2024-09-24T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://lakefs.io/blog/hudi-iceberg-and-delta-lake-data-lake-table-formats-compared/">here</a></span>]]></content>
        <author>
            <name>Oz Katz</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="apache hudi" term="apache hudi"/>
        <category label="apache iceberg" term="apache iceberg"/>
        <category label="delta lake" term="delta lake"/>
        <category label="comparison" term="comparison"/>
        <category label="lakefs" term="lakefs"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hands-on with Apache Hudi and Spark]]></title>
        <id>https://hudi.apache.org/blog/2024/09/22/hands-on-with-apache-hudi-and-spark</id>
        <link href="https://hudi.apache.org/blog/2024/09/22/hands-on-with-apache-hudi-and-spark"/>
        <updated>2024-09-22T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://blog.devgenius.io/hands-on-with-apache-hudi-ce45869b5eff">here</a></span>]]></content>
        <author>
            <name>Sanjeet Shukla</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="Apache Spark" term="Apache Spark"/>
        <category label="devgenius" term="devgenius"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[How Apache Hudi transformed Yuno’s data lake]]></title>
        <id>https://hudi.apache.org/blog/2024/09/17/how-apache-hudi-transformed-yuno-s-data-lake</id>
        <link href="https://hudi.apache.org/blog/2024/09/17/how-apache-hudi-transformed-yuno-s-data-lake"/>
        <updated>2024-09-17T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://www.y.uno/post/how-apache-hudi-transformed-yunos-data-lake">here</a></span>]]></content>
        <author>
            <name>Nahuel Leandro Mazzitelli</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="apache hudi" term="apache hudi"/>
        <category label="cow" term="cow"/>
        <category label="mor" term="mor"/>
        <category label="record index" term="record index"/>
        <category label="record level index" term="record level index"/>
        <category label="clustering" term="clustering"/>
        <category label="cleaning" term="cleaning"/>
        <category label="bloom index" term="bloom index"/>
        <category label="fiel sizing" term="fiel sizing"/>
        <category label="y.uno" term="y.uno"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Uber’s Big Data Revolution: From MySQL to Hadoop and Beyond]]></title>
        <id>https://hudi.apache.org/blog/2024/09/14/Ubers-Big-Data-Revolution-From-MySQL-to-Hadoop-and-Beyond</id>
        <link href="https://hudi.apache.org/blog/2024/09/14/Ubers-Big-Data-Revolution-From-MySQL-to-Hadoop-and-Beyond"/>
        <updated>2024-09-14T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://vutr.substack.com/p/ubers-big-data-revolution-from-mysql">here</a></span>]]></content>
        <author>
            <name>Vu Trinh</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="apache hudi" term="apache hudi"/>
        <category label="use-case" term="use-case"/>
        <category label="substack" term="substack"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Comparing Apache Hudi, Apache Iceberg, and Delta Lake]]></title>
        <id>https://hudi.apache.org/blog/2024/09/11/comparing-apache-hudi-apache-iceberg-and-delta-lake</id>
        <link href="https://hudi.apache.org/blog/2024/09/11/comparing-apache-hudi-apache-iceberg-and-delta-lake"/>
        <updated>2024-09-11T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://www.cloudthat.com/resources/blog/comparing-apache-hudi-apache-iceberg-and-delta-lake">here</a></span>]]></content>
        <author>
            <name>Vasanth Kumar R</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="apache hudi" term="apache hudi"/>
        <category label="apache iceberg" term="apache iceberg"/>
        <category label="delta lake" term="delta lake"/>
        <category label="comparison" term="comparison"/>
        <category label="cloudthat" term="cloudthat"/>
    </entry>
</feed>